{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-07T13:02:21.226429Z",
     "start_time": "2024-04-07T13:02:21.217386Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from flask import Flask, jsonify, request, abort\n",
    "import feedparser\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "def fetch_arxiv_articles(query, max_results=5,id=False):\n",
    "    # Construct the query URL with parameters directly in the string\n",
    "    if id:\n",
    "        query_url = f\"http://export.arxiv.org/api/query?{query}\"\n",
    "    else:\n",
    "        query_url = f\"http://export.arxiv.org/api/query?search_query={query}&start=0&max_results={max_results}&sortBy=lastUpdatedDate&sortOrder=descending\"\n",
    "    response = requests.get(query_url)\n",
    "    print(query_url)  # Print the response text for debugging\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"\"\"\n",
    "    Welcome to the API! This is the homepage. Here are the different endpoints: <br>\n",
    "    /get_data: Fetches a list of articles from the site. Retrieving 5 articles might be sufficient.<br>\n",
    "    /articles: Displays information about the articles, including the article number, title, publication date, etc., but not the content itself.<br>\n",
    "    /article/<\"number\">: Accesses the content of a specified article.<br>\n",
    "    /ml or /ml/<\"number\">: Executes a machine learning script. Depending on the desired goal, it applies to either all articles or a single one. For example, sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Fetches a list of articles from the site. Retrieving 5 articles might be sufficient.\n",
    "@app.route('/get_data', methods=['GET'])\n",
    "def get_data():\n",
    "    articles_xml = fetch_arxiv_articles('cat:cs.AI', max_results=5)\n",
    "    if articles_xml:\n",
    "        feed = feedparser.parse(articles_xml)\n",
    "        articles = []\n",
    "        for entry in feed.entries:\n",
    "            article = {\n",
    "                'title': entry.title,\n",
    "                'authors': [author.name for author in entry.authors],\n",
    "                'link': entry.link,\n",
    "                'published': entry.published,\n",
    "                'number': entry.id[21:],\n",
    "            }\n",
    "            articles.append(article)\n",
    "        return jsonify(articles)\n",
    "    else:\n",
    "        abort(404, description=\"Resource not found\")\n",
    "\n",
    "\n",
    "# Displays information about the articles, including the article number, title, publication date, etc., but not the content itself.\n",
    "@app.route('/articles', methods=['GET'])\n",
    "def get_articles():\n",
    "    articles_xml = fetch_arxiv_articles('cat:cs.AI', max_results=5)\n",
    "    if articles_xml:\n",
    "        feed = feedparser.parse(articles_xml)\n",
    "        articles = []\n",
    "        for entry in feed.entries:\n",
    "            article = {\n",
    "                'title': entry.title,\n",
    "                'summary': entry.summary,\n",
    "                'authors': [author.name for author in entry.authors],\n",
    "                'link': entry.link,\n",
    "                'published': entry.published,\n",
    "                'number': entry.id[21:],\n",
    "            }\n",
    "            articles.append(article)\n",
    "        return jsonify(articles)\n",
    "    else:\n",
    "        abort(404, description=\"Resource not found\")\n",
    "\n",
    "\n",
    "# Accesses the content of a specified article.\n",
    "@app.route('/article/<string:article_number>', methods=['GET'])\n",
    "def get_article(article_number):\n",
    "    article_xml = fetch_arxiv_articles(f'id_list={article_number}', max_results=1, id=True)\n",
    "    if article_xml:\n",
    "        entry = feedparser.parse(article_xml).entries[0]\n",
    "        article = {\n",
    "            'title': entry.title,\n",
    "            'summary': entry.summary,\n",
    "            'authors': [author.name for author in entry.authors],\n",
    "            'link': entry.link,\n",
    "            'published': entry.published,\n",
    "            'number': entry.id[21:]\n",
    "        }\n",
    "        return jsonify(article)\n",
    "    else:\n",
    "        abort(404, description=\"Article not found\")\n",
    "\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Use the VADER sentiment intensity analyzer\n",
    "    scores = sia.polarity_scores(text)\n",
    "    # Determine the sentiment based on the compound score\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound_score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Initialize the VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Use the VADER sentiment intensity analyzer\n",
    "    scores = sia.polarity_scores(text)\n",
    "    # Determine the sentiment based on the compound score\n",
    "    compound_score = scores['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound_score <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "@app.route('/ml/<string:article_number>', methods=['GET'])\n",
    "def machine_learning(article_number=None):\n",
    "    if article_number:\n",
    "        # Apply ML to a single article\n",
    "        # Fetch the article content first\n",
    "        article_xml = fetch_arxiv_articles(f'id_list={article_number}', max_results=1, id=True)\n",
    "        if article_xml:\n",
    "            entry = feedparser.parse(article_xml).entries[0]\n",
    "            article_content = entry.summary\n",
    "            # Apply sentiment analysis to the article content\n",
    "            sentiment = analyze_sentiment(article_content)\n",
    "            return jsonify({'article_number': article_number, 'sentiment': sentiment, 'number': entry.id[21:]})\n",
    "        else:\n",
    "            abort(404, description=\"Article not found\")\n",
    "    else:\n",
    "        # Apply ML to all articles\n",
    "        articles_xml = fetch_arxiv_articles('cat:cs.AI', max_results=10)\n",
    "        if articles_xml:\n",
    "            feed = feedparser.parse(articles_xml)\n",
    "            sentiments = []\n",
    "            for entry in feed.entries:\n",
    "                article_content = entry.summary\n",
    "                sentiment = analyze_sentiment(article_content)\n",
    "                sentiments.append({'title': entry.title, 'sentiment': sentiment, 'number': entry.id[21:]})\n",
    "            return jsonify({'sentiments': sentiments})\n",
    "        else:\n",
    "            abort(404, description=\"Resource not found\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-07T13:04:07.464987Z"
    }
   },
   "id": "bfaa6ea079d9b60",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3D%26id_list%3Dcond-mat%2F0207270v1%26start%3D0%26max_results%3D10\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=&amp;id_list=cond-mat/0207270v1&amp;start=0&amp;max_results=10</title>\n",
      "  <id>http://arxiv.org/api/C0KeZIdyNG94Gv+LuapZg5mEFiE</id>\n",
      "  <updated>2024-04-06T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">1</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">10</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/cond-mat/0207270v1</id>\n",
      "    <updated>2002-07-10T17:10:30Z</updated>\n",
      "    <published>2002-07-10T17:10:30Z</published>\n",
      "    <title>Understanding Paramagnetic Spin Correlations in the Spin-Liquid\n",
      "  Pyrochlore Tb2Ti2O7</title>\n",
      "    <summary>  Recent elastic and inelastic neutron scattering studies of the highly\n",
      "frustrated pyrochlore antiferromagnet Tb2Ti2O7 have shown some very intriguing\n",
      "features that cannot be modeled by the local &lt;111&gt; classical Ising model,\n",
      "naively expected to describe this system at low temperatures. Using the random\n",
      "phase approximation to take into account fluctuations between the ground state\n",
      "doublet and the first excited doublet, we successfully describe the elastic\n",
      "neutron scattering pattern and dispersion relations in Tb2Ti2O7,\n",
      "semi-quantitatively consistent with experimental observations.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Ying-Jer Kao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Matthew Enjalran</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Michel J. P. Gingras</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">revtex4, 4 pages, 1 Color+ 3 BW figures</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/cond-mat/0207270v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/cond-mat/0207270v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cond-mat.dis-nn\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cond-mat.dis-nn\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cond-mat.stat-mech\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n"
     ]
    }
   ],
   "source": [
    "# ex_url = \"http://export.arxiv.org/api/query?id_list=cond-mat/0207270v1\"\n",
    "# response = requests.get(ex_url)\n",
    "# print(response.text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-06T23:32:45.031744Z",
     "start_time": "2024-04-06T23:32:44.603491Z"
    }
   },
   "id": "709a4de67114b987",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
